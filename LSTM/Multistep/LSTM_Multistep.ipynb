{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Multistep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJom4wG9_jlZ"
      },
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VX8Isqs_mx5"
      },
      "source": [
        "#Import Libraries\n",
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-_loNQF_pWC"
      },
      "source": [
        "# date-time parsing function for loading the dataset\n",
        "def parser(x):\n",
        "\treturn datetime.strptime('190'+x, '%Y-%m')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkvVU57N_riG"
      },
      "source": [
        "# convert time series into supervised learning problem\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXlPzKDW_vdp"
      },
      "source": [
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn Series(diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeyoKVch_xdn"
      },
      "source": [
        "# transform series into train and test sets for supervised learning\n",
        "def prepare_data(series, n_test, n_lag, n_seq):\n",
        "\t# extract raw values\n",
        "\traw_values = series.values\n",
        "\t# transform data to be stationary\n",
        "\tdiff_series = difference(raw_values, 1)\n",
        "\tdiff_values = diff_series.values\n",
        "\tdiff_values = diff_values.reshape(len(diff_values), 1)\n",
        "\t# rescale values to -1, 1\n",
        "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\tscaled_values = scaler.fit_transform(diff_values)\n",
        "\tscaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
        "\t# transform into supervised learning problem X, y\n",
        "\tsupervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
        "\tsupervised_values = supervised.values\n",
        "\t# split into train and test sets\n",
        "\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
        "\treturn scaler, train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9RFS8rP_x9a"
      },
      "source": [
        "# fit an LSTM network to training data\n",
        "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
        "\t# reshape training into [samples, timesteps, features]\n",
        "\tX, y = train[:, 0:n_lag], train[:, n_lag:]\n",
        "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\t# design network\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
        "\tmodel.add(Dense(y.shape[1]))\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\t# fit network\n",
        "\tfor i in range(nb_epoch):\n",
        "\t\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
        "\t\tmodel.reset_states()\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki88vo1s_0LL"
      },
      "source": [
        "# make one forecast with an LSTM,\n",
        "def forecast_lstm(model, X, n_batch):\n",
        "\t# reshape input pattern to [samples, timesteps, features]\n",
        "\tX = X.reshape(1, 1, len(X))\n",
        "\t# make forecast\n",
        "\tforecast = model.predict(X, batch_size=n_batch)\n",
        "\t# convert to array\n",
        "\treturn [x for x in forecast[0, :]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoYdJQGZ_2N-"
      },
      "source": [
        "# evaluate the persistence model\n",
        "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
        "\tforecasts = list()\n",
        "\tfor i in range(len(test)):\n",
        "\t\tX, y = test[i, 0:n_lag], test[i, n_lag:]\n",
        "\t\t# make forecast\n",
        "\t\tforecast = forecast_lstm(model, X, n_batch)\n",
        "\t\t# store the forecast\n",
        "\t\tforecasts.append(forecast)\n",
        "\treturn forecasts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0Mr0_O_6CV"
      },
      "source": [
        "# invert differenced forecast\n",
        "def inverse_difference(last_ob, forecast):\n",
        "\t# invert first forecast\n",
        "\tinverted = list()\n",
        "\tinverted.append(forecast[0] + last_ob)\n",
        "\t# propagate difference forecast using inverted first value\n",
        "\tfor i in range(1, len(forecast)):\n",
        "\t\tinverted.append(forecast[i] + inverted[i-1])\n",
        "\treturn inverted\n",
        " \n",
        "# inverse data transform on forecasts\n",
        "def inverse_transform(series, forecasts, scaler, n_test):\n",
        "\tinverted = list()\n",
        "\tfor i in range(len(forecasts)):\n",
        "\t\t# create array from forecast\n",
        "\t\tforecast = array(forecasts[i])\n",
        "\t\tforecast = forecast.reshape(1, len(forecast))\n",
        "\t\t# invert scaling\n",
        "\t\tinv_scale = scaler.inverse_transform(forecast)\n",
        "\t\tinv_scale = inv_scale[0, :]\n",
        "\t\t# invert differencing\n",
        "\t\tindex = len(series) - n_test + i - 1\n",
        "\t\tlast_ob = series.values[index]\n",
        "\t\tinv_diff = inverse_difference(last_ob, inv_scale)\n",
        "\t\t# store\n",
        "\t\tinverted.append(inv_diff)\n",
        "\treturn inverted\n",
        " \n",
        "# evaluate the RMSE for each forecast time step\n",
        "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
        "\tfor i in range(n_seq):\n",
        "\t\tactual = [row[i] for row in test]\n",
        "\t\tpredicted = [forecast[i] for forecast in forecasts]\n",
        "\t\trmse = sqrt(mean_squared_error(actual, predicted))\n",
        "\t\tprint('t+%d RMSE: %f' % ((i+1), rmse))\n",
        " \n",
        "# plot the forecasts in the context of the original dataset\n",
        "def plot_forecasts(series, forecasts, n_test):\n",
        "\t# plot the entire dataset in blue\n",
        "\tpyplot.plot(series.values)\n",
        "\t# plot the forecasts in red\n",
        "\tfor i in range(len(forecasts)):\n",
        "\t\toff_s = len(series) - n_test + i - 1\n",
        "\t\toff_e = off_s + len(forecasts[i]) + 1\n",
        "\t\txaxis = [x for x in range(off_s, off_e)]\n",
        "\t\tyaxis = [series.values[off_s]] + forecasts[i]\n",
        "\t\tpyplot.plot(xaxis, yaxis, color='red')\n",
        "\t# show the plot\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRStV0dG_6mM"
      },
      "source": [
        "# load dataset\n",
        "series = read_csv('/content/drive/MyDrive/shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "# configure\n",
        "n_lag = 1\n",
        "n_seq = 3\n",
        "n_test = 10\n",
        "n_epochs = 1500\n",
        "n_batch = 1\n",
        "n_neurons = 1\n",
        "# prepare data\n",
        "scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
        "# fit model\n",
        "model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)\n",
        "model_url = '/content/drive/MyDrive/model_multistep.h5'\n",
        "model.save(model_url)\n",
        "print(\"Saved\")\n",
        "# make forecasts\n",
        "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n",
        "# inverse transform forecasts and test\n",
        "forecasts = inverse_transform(series, forecasts, scaler, n_test+2)\n",
        "actual = [row[n_lag:] for row in test]\n",
        "actual = inverse_transform(series, actual, scaler, n_test+2)\n",
        "# evaluate forecasts\n",
        "evaluate_forecasts(actual, forecasts, n_lag, n_seq)\n",
        "# plot forecasts\n",
        "plot_forecasts(series, forecasts, n_test+2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}