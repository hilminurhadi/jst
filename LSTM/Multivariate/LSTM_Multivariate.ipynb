{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Multivariate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHC4r4E6Rkmx"
      },
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJD9VMkyRwtj"
      },
      "source": [
        "#Import Libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Bidirectional, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MPBJRJxR0GY"
      },
      "source": [
        "def preprocess_data(file_path):\n",
        "  \"\"\"function that preprocesses the data from the dataset\"\"\"\n",
        "  df = pd.read_csv(file_path)\n",
        "  # Remove all NaN-containing entries\n",
        "  df = df.dropna()\n",
        "  # Reformat the timestamp\n",
        "  df['Timestamp'] = pd.to_datetime(df['Timestamp'],\n",
        "  infer_datetime_format=True, unit='s')\n",
        "  # Use the timestamp as index column\n",
        "  df = df.set_index('Timestamp')\n",
        "  # Narrow the scope of dataframe columns to work with\n",
        "  df = df.drop(['Low', 'High', 'Volume_(BTC)', 'Weighted_Price'], \n",
        "               axis=1)\n",
        "  # Reorder columns\n",
        "  df = df.reindex(columns=['Open', 'Close', 'Volume_(Currency)'])\n",
        "  # Work on a 1hour window\n",
        "  df['Open'] = df['Open'].resample('1H').first()\n",
        "  df['Close'] = df['Close'].resample('1H').last()\n",
        "  df['Volume_(Currency)'] = df['Volume_(Currency)'].resample('1H').sum()\n",
        "  # Remove all NaN-containing entries\n",
        "  df = df.dropna()\n",
        "  # Remove the first half of the dataframe (given data sparsity)\n",
        "  df = df.iloc[-int((df.shape[0]/2)):]\n",
        "  print(df.head(10))\n",
        "  print('=======================')\n",
        "  # Create the dataset (np.ndarray of \"df.shape\")\n",
        "  dataset = df.values\n",
        "  print(dataset[:10])\n",
        "  print(dataset.shape)\n",
        "  print('=======================')\n",
        "  # Standardize the dataset\n",
        "  mean = np.mean(dataset, axis=0)\n",
        "  stddev = np.std(dataset, axis=0)\n",
        "  dataset = (dataset - mean) / stddev\n",
        "  print(dataset[:10])\n",
        "  print(dataset.shape)\n",
        "  print('=======================')\n",
        "  def split_sequence(sequence, n_steps):\n",
        "    \"\"\"function that splits a dataset sequence into input data and\n",
        "    labels\"\"\"\n",
        "    X, Y = [], []\n",
        "    for i in range(sequence.shape[0]):\n",
        "      if (i + n_steps) >= sequence.shape[0]:\n",
        "        break\n",
        "      # Divide sequence between data (input) and labels (output)\n",
        "      seq_X, seq_Y = sequence[i: i + n_steps],sequence[i + n_steps, -2]\n",
        "      X.append(seq_X)\n",
        "      Y.append(seq_Y)\n",
        "    return np.array(X), np.array(Y)\n",
        "  # Create training and validation datasets\n",
        "  dataset_size = dataset.shape[0]\n",
        "  x_train, y_train = split_sequence(dataset[0: math.ceil(0.7 *\n",
        "                                    dataset_size)], 24)\n",
        "  x_val, y_val = split_sequence(dataset[math.floor(0.7 *\n",
        "                                dataset_size):], 24)\n",
        "  return dataset, df, x_train, y_train, x_val, y_val\n",
        "\n",
        "file_path = '/content/drive/MyDrive/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv'\n",
        "dataset, df, x_train, y_train, x_val, y_val = preprocess_data(file_path)\n",
        "print(\"dataset.shape: {}\".format(dataset.shape))\n",
        "print(\"df.shape: {}\".format(df.shape))\n",
        "print(\"x_train.shape: {}\".format(x_train.shape))\n",
        "print(\"y_train.shape: {}\".format(y_train.shape))\n",
        "print(\"x_val.shape: {}\".format(x_val.shape))\n",
        "print(\"y_val.shape: {}\".format(y_val.shape))\n",
        "print('=======================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJefwfVR3U_"
      },
      "source": [
        "def plot_0(df, title):\n",
        "  \"\"\"function that plots Price at Close vs. Timestamp\"\"\"\n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.plot(df)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Timestamp')\n",
        "  plt.ylabel('Price at Close (USD)')\n",
        "\n",
        "  plt.show()\n",
        "plot_0(df['Close'], 'BTC: Price at Close vs. Timestamp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nyZhjscR5rQ"
      },
      "source": [
        "batch_size = 256\n",
        "buffer_size = x_train.shape[0]\n",
        "# Provide an infinite dataset\n",
        "train_iterator = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size).batch(batch_size).repeat()\n",
        "# Provide an infinite dataset\n",
        "val_iterator = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO1dzN_JR8Dh"
      },
      "source": [
        "#Build Model\n",
        "n_steps = x_train.shape[-2]\n",
        "n_features = x_train.shape[-1]\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(64, activation='relu', input_shape=(n_steps, n_features))))\n",
        "model.add(Dense(1))\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXqU6jI1R-V_"
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoch = 100\n",
        "validation_steps = 10\n",
        "# Train with an infinite dataset\n",
        "history = model.fit(train_iterator, epochs=epochs,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=val_iterator,\n",
        "                    validation_steps=validation_steps)\n",
        "print('=======================')\n",
        "model_url = '/content/drive/MyDrive/model_multivariate.h5'\n",
        "model.save(model_url)\n",
        "print(\"Saved\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRDIRjrRSBS2"
      },
      "source": [
        "#Plot Grafik\n",
        "def plot_1(history, title):\n",
        "  \"\"\"function that plots the loss results of the model\"\"\"\n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.plot(history.history['loss'], 'o-', mfc='none', markersize=10, \n",
        "  label='Train')\n",
        "  plt.plot(history.history['val_loss'], 'o-', mfc='none', \n",
        "  markersize=10, label='Valid')\n",
        "  plt.title('LSTM Model Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "def plot_2(data_24h, single_label, single_prediction, title):\n",
        "  \"\"\"function that plots a single-step price prediction following \n",
        "  24h of data\"\"\"\n",
        "  time_steps = list(range(24))\n",
        "  next_step = 24\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(time_steps, data_24h, 'o-', markersize=8, \n",
        "  label='data_24h')\n",
        "  plt.plot(next_step, single_label, 'b+', mfc='none', markersize=12, \n",
        "  label='Label')\n",
        "  plt.plot(next_step, single_prediction, 'ro', mfc='none', \n",
        "  markersize=12, label='Prediction')\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Time Steps')\n",
        "  plt.ylabel('Price at Close (Standardized Data)')\n",
        "  plt.legend()\n",
        "  plt.show\n",
        "def plot_3(future, prediction, title):\n",
        "  \"\"\"function that plots predictions over \"batch_size\" x 24h \n",
        "  timeframes\"\"\"\n",
        "  days = list(range(1, future.shape[0] + 1))\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.plot(days, future, 'o-', markersize=5, mfc='none', \n",
        "  label='Labels')\n",
        "  plt.plot(days, prediction, 'o-', markersize=5, mfc='none', \n",
        "  label='Predictions')\n",
        "  plt.title(title)\n",
        "  plt.xlim([days[0], days[-1]])\n",
        "  plt.xlabel('24h Steps')\n",
        "  plt.ylabel('Price at Close (Standardized Data)')\n",
        "  plt.legend()\n",
        "  plt.show\n",
        "# Plot the model loss results\n",
        "plot_1(history, 'Training / Validation Losses from History')\n",
        "# Make a single-step price prediction following 24h of data\n",
        "window_num = 0\n",
        "# Make predictions over \"batch_size\" x 24h timeframes\n",
        "string = 'Predictions over a {} x 24h Timeframe (Batch {})'\n",
        "for batch_num, (x, y) in enumerate(val_iterator.take(3)):\n",
        "  title = string.format(batch_size, batch_num)\n",
        "  plot_3(y.numpy(),\n",
        "         model.predict(x).reshape(-1),\n",
        "         title)\n",
        "  batch_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}